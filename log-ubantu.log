/xqs/software/anaconda3/envs/AudioClassification/bin/python /home/qishengxu/桌面/AudioClassification/train.py
-----------  Configuration Arguments -----------
audio_duration: 3
augment_conf_path: configs/augment.yml
batch_size: 16
feature_method: melspectrogram
learning_rate: 0.001
min_duration: 0.5
num_classes: 10
num_epoch: 30
num_workers: 4
resume: None
save_model_dir: output/models/
test_list_path: dataset/test_list.txt
train_list_path: dataset/train_list.txt
use_model: ecapa_tdnn
------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 512, 98]         204,800
       BatchNorm1d-2              [-1, 512, 98]           1,024
      Conv1dReluBn-3              [-1, 512, 98]               0
            Conv1d-4              [-1, 512, 98]         262,144
       BatchNorm1d-5              [-1, 512, 98]           1,024
      Conv1dReluBn-6              [-1, 512, 98]               0
            Conv1d-7               [-1, 64, 98]          12,288
       BatchNorm1d-8               [-1, 64, 98]             128
            Conv1d-9               [-1, 64, 98]          12,288
      BatchNorm1d-10               [-1, 64, 98]             128
           Conv1d-11               [-1, 64, 98]          12,288
      BatchNorm1d-12               [-1, 64, 98]             128
           Conv1d-13               [-1, 64, 98]          12,288
      BatchNorm1d-14               [-1, 64, 98]             128
           Conv1d-15               [-1, 64, 98]          12,288
      BatchNorm1d-16               [-1, 64, 98]             128
           Conv1d-17               [-1, 64, 98]          12,288
      BatchNorm1d-18               [-1, 64, 98]             128
           Conv1d-19               [-1, 64, 98]          12,288
      BatchNorm1d-20               [-1, 64, 98]             128
 Res2Conv1dReluBn-21              [-1, 512, 98]               0
           Conv1d-22              [-1, 512, 98]         262,144
      BatchNorm1d-23              [-1, 512, 98]           1,024
     Conv1dReluBn-24              [-1, 512, 98]               0
           Linear-25                  [-1, 256]         131,328
           Linear-26                  [-1, 512]         131,584
       SE_Connect-27              [-1, 512, 98]               0
           Conv1d-28              [-1, 512, 98]         262,144
      BatchNorm1d-29              [-1, 512, 98]           1,024
     Conv1dReluBn-30              [-1, 512, 98]               0
           Conv1d-31               [-1, 64, 98]          12,288
      BatchNorm1d-32               [-1, 64, 98]             128
           Conv1d-33               [-1, 64, 98]          12,288
      BatchNorm1d-34               [-1, 64, 98]             128
           Conv1d-35               [-1, 64, 98]          12,288
      BatchNorm1d-36               [-1, 64, 98]             128
           Conv1d-37               [-1, 64, 98]          12,288
      BatchNorm1d-38               [-1, 64, 98]             128
           Conv1d-39               [-1, 64, 98]          12,288
      BatchNorm1d-40               [-1, 64, 98]             128
           Conv1d-41               [-1, 64, 98]          12,288
      BatchNorm1d-42               [-1, 64, 98]             128
           Conv1d-43               [-1, 64, 98]          12,288
      BatchNorm1d-44               [-1, 64, 98]             128
 Res2Conv1dReluBn-45              [-1, 512, 98]               0
           Conv1d-46              [-1, 512, 98]         262,144
      BatchNorm1d-47              [-1, 512, 98]           1,024
     Conv1dReluBn-48              [-1, 512, 98]               0
           Linear-49                  [-1, 256]         131,328
           Linear-50                  [-1, 512]         131,584
       SE_Connect-51              [-1, 512, 98]               0
           Conv1d-52              [-1, 512, 98]         262,144
      BatchNorm1d-53              [-1, 512, 98]           1,024
     Conv1dReluBn-54              [-1, 512, 98]               0
           Conv1d-55               [-1, 64, 98]          12,288
      BatchNorm1d-56               [-1, 64, 98]             128
           Conv1d-57               [-1, 64, 98]          12,288
      BatchNorm1d-58               [-1, 64, 98]             128
           Conv1d-59               [-1, 64, 98]          12,288
      BatchNorm1d-60               [-1, 64, 98]             128
           Conv1d-61               [-1, 64, 98]          12,288
      BatchNorm1d-62               [-1, 64, 98]             128
           Conv1d-63               [-1, 64, 98]          12,288
      BatchNorm1d-64               [-1, 64, 98]             128
           Conv1d-65               [-1, 64, 98]          12,288
      BatchNorm1d-66               [-1, 64, 98]             128
           Conv1d-67               [-1, 64, 98]          12,288
      BatchNorm1d-68               [-1, 64, 98]             128
 Res2Conv1dReluBn-69              [-1, 512, 98]               0
           Conv1d-70              [-1, 512, 98]         262,144
      BatchNorm1d-71              [-1, 512, 98]           1,024
     Conv1dReluBn-72              [-1, 512, 98]               0
           Linear-73                  [-1, 256]         131,328
           Linear-74                  [-1, 512]         131,584
       SE_Connect-75              [-1, 512, 98]               0
           Conv1d-76             [-1, 1536, 98]       2,360,832
           Conv1d-77              [-1, 128, 98]         196,736
           Conv1d-78             [-1, 1536, 98]         198,144
AttentiveStatsPool-79                 [-1, 3072]               0
      BatchNorm1d-80                 [-1, 3072]           6,144
           Linear-81                  [-1, 192]         590,016
      BatchNorm1d-82                  [-1, 192]             384
           Linear-83                   [-1, 10]           1,930
================================================================
Total params: 6,188,490
Trainable params: 6,188,490
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.03
Forward/backward pass size (MB): 14.81
Params size (MB): 23.61
Estimated Total Size (MB): 38.44
----------------------------------------------------------------
[2022-11-10 20:19:44.108259] Train epoch [0/30], batch: 0/530, lr: 0.00100000, loss: 2.39391780, accuracy: 0.18750000, eta: 21:41:45
[2022-11-10 20:21:21.939187] Train epoch [0/30], batch: 100/530, lr: 0.00100000, loss: 1.76673186, accuracy: 0.39789604, eta: 4:27:52
[2022-11-10 20:22:51.886118] Train epoch [0/30], batch: 200/530, lr: 0.00100000, loss: 1.59971642, accuracy: 0.45553483, eta: 4:10:50
[2022-11-10 20:24:24.895227] Train epoch [0/30], batch: 300/530, lr: 0.00100000, loss: 1.51638258, accuracy: 0.48608804, eta: 4:06:46
[2022-11-10 20:25:59.691230] Train epoch [0/30], batch: 400/530, lr: 0.00100000, loss: 1.44419789, accuracy: 0.51215711, eta: 4:05:07
[2022-11-10 20:27:31.880581] Train epoch [0/30], batch: 500/530, lr: 0.00100000, loss: 1.38761950, accuracy: 0.53343313, eta: 4:02:09
======================================================================
[2022-11-10 20:28:02.517444] Test 0, Accuracy: 0.6909722222222222
======================================================================
[2022-11-10 20:28:06.689230] Train epoch [1/30], batch: 0/530, lr: 0.00099726, loss: 1.45441318, accuracy: 0.43750000, eta: 16:50:52
[2022-11-10 20:29:40.850224] Train epoch [1/30], batch: 100/530, lr: 0.00099726, loss: 1.11402512, accuracy: 0.63985149, eta: 4:07:12
[2022-11-10 20:31:15.413874] Train epoch [1/30], batch: 200/530, lr: 0.00099726, loss: 1.08075285, accuracy: 0.64738806, eta: 4:02:21
[2022-11-10 20:32:50.676889] Train epoch [1/30], batch: 300/530, lr: 0.00099726, loss: 1.08087349, accuracy: 0.64140365, eta: 4:00:15
[2022-11-10 20:34:20.020097] Train epoch [1/30], batch: 400/530, lr: 0.00099726, loss: 1.06199253, accuracy: 0.64713217, eta: 3:54:44
[2022-11-10 20:35:53.357837] Train epoch [1/30], batch: 500/530, lr: 0.00099726, loss: 1.05587530, accuracy: 0.64995010, eta: 3:52:47
======================================================================
[2022-11-10 20:36:26.881607] Test 1, Accuracy: 0.6527777777777778
======================================================================
[2022-11-10 20:36:31.558814] Train epoch [2/30], batch: 0/530, lr: 0.00098907, loss: 0.91895485, accuracy: 0.68750000, eta: 18:20:23
[2022-11-10 20:38:04.212877] Train epoch [2/30], batch: 100/530, lr: 0.00098907, loss: 0.95837951, accuracy: 0.68316832, eta: 3:56:11
[2022-11-10 20:39:39.469890] Train epoch [2/30], batch: 200/530, lr: 0.00098907, loss: 0.93732035, accuracy: 0.68750000, eta: 3:53:30
[2022-11-10 20:41:10.829311] Train epoch [2/30], batch: 300/530, lr: 0.00098907, loss: 0.95406324, accuracy: 0.68106312, eta: 3:48:25
[2022-11-10 20:42:44.161764] Train epoch [2/30], batch: 400/530, lr: 0.00098907, loss: 0.94596118, accuracy: 0.68640898, eta: 3:46:17
[2022-11-10 20:44:16.455124] Train epoch [2/30], batch: 500/530, lr: 0.00098907, loss: 0.95241880, accuracy: 0.68438124, eta: 3:43:53
======================================================================
[2022-11-10 20:44:47.362450] Test 2, Accuracy: 0.8263888888888888
======================================================================
[2022-11-10 20:44:52.142675] Train epoch [3/30], batch: 0/530, lr: 0.00097553, loss: 0.55802017, accuracy: 0.75000000, eta: 18:07:42
[2022-11-10 20:46:24.800784] Train epoch [3/30], batch: 100/530, lr: 0.00097553, loss: 0.78600323, accuracy: 0.75556931, eta: 3:47:57
[2022-11-10 20:47:58.857252] Train epoch [3/30], batch: 200/530, lr: 0.00097553, loss: 0.82884026, accuracy: 0.72636816, eta: 3:43:47
[2022-11-10 20:49:31.033388] Train epoch [3/30], batch: 300/530, lr: 0.00097553, loss: 0.84120518, accuracy: 0.72487542, eta: 3:39:53
[2022-11-10 20:51:03.318992] Train epoch [3/30], batch: 400/530, lr: 0.00097553, loss: 0.82719940, accuracy: 0.72911471, eta: 3:37:13
[2022-11-10 20:52:38.217596] Train epoch [3/30], batch: 500/530, lr: 0.00097553, loss: 0.82475710, accuracy: 0.72991517, eta: 3:36:12
======================================================================
[2022-11-10 20:53:10.551313] Test 3, Accuracy: 0.7083333333333334
======================================================================
[2022-11-10 20:53:15.294278] Train epoch [4/30], batch: 0/530, lr: 0.00095677, loss: 0.41227353, accuracy: 0.81250000, eta: 17:19:40
[2022-11-10 20:54:45.129607] Train epoch [4/30], batch: 100/530, lr: 0.00095677, loss: 0.76258695, accuracy: 0.75123762, eta: 3:33:00
[2022-11-10 20:56:18.953514] Train epoch [4/30], batch: 200/530, lr: 0.00095677, loss: 0.77441913, accuracy: 0.74533582, eta: 3:31:54
[2022-11-10 20:57:52.892743] Train epoch [4/30], batch: 300/530, lr: 0.00095677, loss: 0.78009385, accuracy: 0.74397841, eta: 3:30:34
[2022-11-10 20:59:25.173638] Train epoch [4/30], batch: 400/530, lr: 0.00095677, loss: 0.79006004, accuracy: 0.74314214, eta: 3:28:12
[2022-11-10 21:00:57.719427] Train epoch [4/30], batch: 500/530, lr: 0.00095677, loss: 0.79157686, accuracy: 0.74176647, eta: 3:26:17
======================================================================
[2022-11-10 21:01:28.781365] Test 4, Accuracy: 0.84375
======================================================================
[2022-11-10 21:01:33.282777] Train epoch [5/30], batch: 0/530, lr: 0.00093301, loss: 0.79405129, accuracy: 0.81250000, eta: 15:47:05
[2022-11-10 21:03:05.654754] Train epoch [5/30], batch: 100/530, lr: 0.00093301, loss: 0.71208459, accuracy: 0.76485149, eta: 3:29:44
[2022-11-10 21:04:40.952411] Train epoch [5/30], batch: 200/530, lr: 0.00093301, loss: 0.73253810, accuracy: 0.75404229, eta: 3:27:42
[2022-11-10 21:06:13.355422] Train epoch [5/30], batch: 300/530, lr: 0.00093301, loss: 0.72656548, accuracy: 0.75934385, eta: 3:23:53
[2022-11-10 21:07:46.205362] Train epoch [5/30], batch: 400/530, lr: 0.00093301, loss: 0.71543556, accuracy: 0.76324813, eta: 3:21:27
[2022-11-10 21:09:18.391058] Train epoch [5/30], batch: 500/530, lr: 0.00093301, loss: 0.71942782, accuracy: 0.76185130, eta: 3:19:05
======================================================================
[2022-11-10 21:09:48.719497] Test 5, Accuracy: 0.7743055555555555
======================================================================
[2022-11-10 21:09:52.787665] Train epoch [6/30], batch: 0/530, lr: 0.00090451, loss: 1.06443584, accuracy: 0.43750000, eta: 13:31:08
[2022-11-10 21:11:25.671375] Train epoch [6/30], batch: 100/530, lr: 0.00090451, loss: 0.72830623, accuracy: 0.75185644, eta: 3:21:23
[2022-11-10 21:12:56.831726] Train epoch [6/30], batch: 200/530, lr: 0.00090451, loss: 0.70175654, accuracy: 0.75870647, eta: 3:15:02
[2022-11-10 21:14:31.565863] Train epoch [6/30], batch: 300/530, lr: 0.00090451, loss: 0.68781286, accuracy: 0.76681894, eta: 3:14:20
[2022-11-10 21:16:04.909864] Train epoch [6/30], batch: 400/530, lr: 0.00090451, loss: 0.69604373, accuracy: 0.76309227, eta: 3:12:30
[2022-11-10 21:17:38.861962] Train epoch [6/30], batch: 500/530, lr: 0.00090451, loss: 0.68283612, accuracy: 0.77033433, eta: 3:11:00
======================================================================
[2022-11-10 21:18:08.544433] Test 6, Accuracy: 0.8020833333333334
======================================================================
[2022-11-10 21:18:12.901461] Train epoch [7/30], batch: 0/530, lr: 0.00087157, loss: 0.58838999, accuracy: 0.75000000, eta: 14:00:09
[2022-11-10 21:19:45.725120] Train epoch [7/30], batch: 100/530, lr: 0.00087157, loss: 0.55951077, accuracy: 0.81559406, eta: 3:13:26
[2022-11-10 21:21:17.760707] Train epoch [7/30], batch: 200/530, lr: 0.00087157, loss: 0.58822960, accuracy: 0.80565920, eta: 3:07:53
[2022-11-10 21:22:49.746661] Train epoch [7/30], batch: 300/530, lr: 0.00087157, loss: 0.60645896, accuracy: 0.80128738, eta: 3:04:59
[2022-11-10 21:24:25.731956] Train epoch [7/30], batch: 400/530, lr: 0.00087157, loss: 0.61103708, accuracy: 0.79816085, eta: 3:04:43
[2022-11-10 21:25:56.277123] Train epoch [7/30], batch: 500/530, lr: 0.00087157, loss: 0.62042105, accuracy: 0.79316367, eta: 3:01:48
======================================================================
[2022-11-10 21:26:28.159885] Test 7, Accuracy: 0.8055555555555555
======================================================================
[2022-11-10 21:26:32.379162] Train epoch [8/30], batch: 0/530, lr: 0.00083457, loss: 0.63677478, accuracy: 0.81250000, eta: 12:55:20
[2022-11-10 21:28:06.804276] Train epoch [8/30], batch: 100/530, lr: 0.00083457, loss: 0.62684643, accuracy: 0.79455446, eta: 3:07:44
[2022-11-10 21:29:40.388878] Train epoch [8/30], batch: 200/530, lr: 0.00083457, loss: 0.62584132, accuracy: 0.79446517, eta: 3:02:26
[2022-11-10 21:31:13.479952] Train epoch [8/30], batch: 300/530, lr: 0.00083457, loss: 0.60742795, accuracy: 0.80107973, eta: 2:59:19
[2022-11-10 21:32:46.062341] Train epoch [8/30], batch: 400/530, lr: 0.00083457, loss: 0.59585708, accuracy: 0.80470698, eta: 2:56:44
[2022-11-10 21:34:18.412845] Train epoch [8/30], batch: 500/530, lr: 0.00083457, loss: 0.59657240, accuracy: 0.80551397, eta: 2:54:29
======================================================================
[2022-11-10 21:34:49.596498] Test 8, Accuracy: 0.8263888888888888
======================================================================
[2022-11-10 21:34:53.607825] Train epoch [9/30], batch: 0/530, lr: 0.00079389, loss: 0.71464849, accuracy: 0.81250000, eta: 11:35:14
[2022-11-10 21:36:27.112559] Train epoch [9/30], batch: 100/530, lr: 0.00079389, loss: 0.54954654, accuracy: 0.81683168, eta: 2:57:00
[2022-11-10 21:38:02.503443] Train epoch [9/30], batch: 200/530, lr: 0.00079389, loss: 0.53851777, accuracy: 0.82338308, eta: 2:54:35
[2022-11-10 21:39:33.679977] Train epoch [9/30], batch: 300/530, lr: 0.00079389, loss: 0.53803790, accuracy: 0.82578904, eta: 2:50:11
[2022-11-10 21:41:06.877534] Train epoch [9/30], batch: 400/530, lr: 0.00079389, loss: 0.54403627, accuracy: 0.82309850, eta: 2:48:07
[2022-11-10 21:42:37.820533] Train epoch [9/30], batch: 500/530, lr: 0.00079389, loss: 0.55109823, accuracy: 0.81986028, eta: 2:45:28
======================================================================
[2022-11-10 21:43:08.056617] Test 9, Accuracy: 0.90625
======================================================================
[2022-11-10 21:43:12.729585] Train epoch [10/30], batch: 0/530, lr: 0.00075000, loss: 0.44649142, accuracy: 0.81250000, eta: 13:06:02
[2022-11-10 21:44:44.534792] Train epoch [10/30], batch: 100/530, lr: 0.00075000, loss: 0.52749801, accuracy: 0.81621287, eta: 2:46:46
[2022-11-10 21:46:16.363762] Train epoch [10/30], batch: 200/530, lr: 0.00075000, loss: 0.53081620, accuracy: 0.82276119, eta: 2:42:11
[2022-11-10 21:47:49.972427] Train epoch [10/30], batch: 300/530, lr: 0.00075000, loss: 0.50508440, accuracy: 0.83305648, eta: 2:40:39
[2022-11-10 21:49:23.617083] Train epoch [10/30], batch: 400/530, lr: 0.00075000, loss: 0.51518238, accuracy: 0.83042394, eta: 2:39:07
[2022-11-10 21:50:55.974066] Train epoch [10/30], batch: 500/530, lr: 0.00075000, loss: 0.52463233, accuracy: 0.82771956, eta: 2:37:08
======================================================================
[2022-11-10 21:51:27.120472] Test 10, Accuracy: 0.8368055555555555
======================================================================
[2022-11-10 21:51:31.139017] Train epoch [11/30], batch: 0/530, lr: 0.00070337, loss: 0.48246846, accuracy: 0.81250000, eta: 10:36:27
[2022-11-10 21:53:05.842313] Train epoch [11/30], batch: 100/530, lr: 0.00070337, loss: 0.45429999, accuracy: 0.84715347, eta: 2:42:02
[2022-11-10 21:54:39.151961] Train epoch [11/30], batch: 200/530, lr: 0.00070337, loss: 0.45142817, accuracy: 0.84732587, eta: 2:36:58
[2022-11-10 21:56:13.502486] Train epoch [11/30], batch: 300/530, lr: 0.00070337, loss: 0.44357836, accuracy: 0.85215947, eta: 2:34:48
[2022-11-10 21:57:46.422654] Train epoch [11/30], batch: 400/530, lr: 0.00070337, loss: 0.44619322, accuracy: 0.85068579, eta: 2:32:21
[2022-11-10 21:59:17.524064] Train epoch [11/30], batch: 500/530, lr: 0.00070337, loss: 0.45086536, accuracy: 0.84967565, eta: 2:29:40
======================================================================
[2022-11-10 21:59:48.705362] Test 11, Accuracy: 0.9166666666666666
======================================================================
[2022-11-10 21:59:53.955490] Train epoch [12/30], batch: 0/530, lr: 0.00065451, loss: 0.42983413, accuracy: 0.81250000, eta: 13:19:39
[2022-11-10 22:01:27.465769] Train epoch [12/30], batch: 100/530, lr: 0.00065451, loss: 0.42146251, accuracy: 0.86571782, eta: 2:33:30
[2022-11-10 22:02:59.194642] Train epoch [12/30], batch: 200/530, lr: 0.00065451, loss: 0.42114830, accuracy: 0.86504975, eta: 2:27:21
[2022-11-10 22:04:31.413752] Train epoch [12/30], batch: 300/530, lr: 0.00065451, loss: 0.43082193, accuracy: 0.86212625, eta: 2:24:31
[2022-11-10 22:06:05.194112] Train epoch [12/30], batch: 400/530, lr: 0.00065451, loss: 0.42800468, accuracy: 0.86237531, eta: 2:22:56
[2022-11-10 22:07:36.453055] Train epoch [12/30], batch: 500/530, lr: 0.00065451, loss: 0.43739384, accuracy: 0.85915669, eta: 2:20:35
======================================================================
[2022-11-10 22:08:08.560736] Test 12, Accuracy: 0.875
======================================================================
[2022-11-10 22:08:13.087820] Train epoch [13/30], batch: 0/530, lr: 0.00060396, loss: 0.50223213, accuracy: 0.75000000, eta: 10:45:37
[2022-11-10 22:09:46.207032] Train epoch [13/30], batch: 100/530, lr: 0.00060396, loss: 0.39258051, accuracy: 0.87376238, eta: 2:23:14
[2022-11-10 22:11:21.652117] Train epoch [13/30], batch: 200/530, lr: 0.00060396, loss: 0.41456357, accuracy: 0.86411692, eta: 2:20:53
[2022-11-10 22:12:54.550368] Train epoch [13/30], batch: 300/530, lr: 0.00060396, loss: 0.40285510, accuracy: 0.86773256, eta: 2:17:48
[2022-11-10 22:14:25.526288] Train epoch [13/30], batch: 400/530, lr: 0.00060396, loss: 0.40496844, accuracy: 0.86736284, eta: 2:14:48
[2022-11-10 22:15:55.942814] Train epoch [13/30], batch: 500/530, lr: 0.00060396, loss: 0.41333583, accuracy: 0.86427146, eta: 2:12:14
======================================================================
[2022-11-10 22:16:28.304191] Test 13, Accuracy: 0.90625
======================================================================
[2022-11-10 22:16:32.474010] Train epoch [14/30], batch: 0/530, lr: 0.00055226, loss: 0.49684662, accuracy: 0.62500000, eta: 9:17:48
[2022-11-10 22:18:04.157568] Train epoch [14/30], batch: 100/530, lr: 0.00055226, loss: 0.32801697, accuracy: 0.89356436, eta: 2:12:14
[2022-11-10 22:19:37.068992] Train epoch [14/30], batch: 200/530, lr: 0.00055226, loss: 0.34531137, accuracy: 0.89023632, eta: 2:09:26
[2022-11-10 22:21:10.045012] Train epoch [14/30], batch: 300/530, lr: 0.00055226, loss: 0.36357829, accuracy: 0.88517442, eta: 2:07:30
[2022-11-10 22:22:45.034593] Train epoch [14/30], batch: 400/530, lr: 0.00055226, loss: 0.36780939, accuracy: 0.88216958, eta: 2:06:26
[2022-11-10 22:24:18.696724] Train epoch [14/30], batch: 500/530, lr: 0.00055226, loss: 0.37017444, accuracy: 0.88173653, eta: 2:04:48
======================================================================
[2022-11-10 22:24:51.824474] Test 14, Accuracy: 0.90625
======================================================================
[2022-11-10 22:24:56.261246] Train epoch [15/30], batch: 0/530, lr: 0.00050000, loss: 0.30188805, accuracy: 0.87500000, eta: 9:15:41
[2022-11-10 22:26:28.158590] Train epoch [15/30], batch: 100/530, lr: 0.00050000, loss: 0.31093097, accuracy: 0.89727723, eta: 2:04:28
[2022-11-10 22:28:02.186519] Train epoch [15/30], batch: 200/530, lr: 0.00050000, loss: 0.32303494, accuracy: 0.89552239, eta: 2:02:10
[2022-11-10 22:29:35.161348] Train epoch [15/30], batch: 300/530, lr: 0.00050000, loss: 0.32324919, accuracy: 0.89368771, eta: 1:59:54
[2022-11-10 22:31:09.678903] Train epoch [15/30], batch: 400/530, lr: 0.00050000, loss: 0.33294141, accuracy: 0.89089776, eta: 1:58:29
[2022-11-10 22:32:42.305787] Train epoch [15/30], batch: 500/530, lr: 0.00050000, loss: 0.34119910, accuracy: 0.88809880, eta: 1:56:32
======================================================================
[2022-11-10 22:33:14.129604] Test 15, Accuracy: 0.8854166666666666
======================================================================
[2022-11-10 22:33:18.448964] Train epoch [16/30], batch: 0/530, lr: 0.00044774, loss: 0.52133608, accuracy: 0.87500000, eta: 8:24:54
[2022-11-10 22:34:52.226689] Train epoch [16/30], batch: 100/530, lr: 0.00044774, loss: 0.29775012, accuracy: 0.90099010, eta: 1:58:12
[2022-11-10 22:36:23.901985] Train epoch [16/30], batch: 200/530, lr: 0.00044774, loss: 0.30797887, accuracy: 0.89427861, eta: 1:53:28
[2022-11-10 22:37:57.682257] Train epoch [16/30], batch: 300/530, lr: 0.00044774, loss: 0.31173441, accuracy: 0.89534884, eta: 1:51:41
[2022-11-10 22:39:30.418154] Train epoch [16/30], batch: 400/530, lr: 0.00044774, loss: 0.33222142, accuracy: 0.89074190, eta: 1:49:43
[2022-11-10 22:41:02.762457] Train epoch [16/30], batch: 500/530, lr: 0.00044774, loss: 0.33837974, accuracy: 0.88809880, eta: 1:47:49
======================================================================
[2022-11-10 22:41:35.480474] Test 16, Accuracy: 0.9166666666666666
======================================================================
[2022-11-10 22:41:39.763819] Train epoch [17/30], batch: 0/530, lr: 0.00039604, loss: 0.24103580, accuracy: 0.87500000, eta: 7:43:52
[2022-11-10 22:43:13.687867] Train epoch [17/30], batch: 100/530, lr: 0.00039604, loss: 0.30155703, accuracy: 0.91027228, eta: 1:49:43
[2022-11-10 22:44:45.428605] Train epoch [17/30], batch: 200/530, lr: 0.00039604, loss: 0.28490129, accuracy: 0.91417910, eta: 1:45:12
[2022-11-10 22:46:17.406141] Train epoch [17/30], batch: 300/530, lr: 0.00039604, loss: 0.28550711, accuracy: 0.91258306, eta: 1:42:46
[2022-11-10 22:47:52.518385] Train epoch [17/30], batch: 400/530, lr: 0.00039604, loss: 0.28667569, accuracy: 0.91209476, eta: 1:41:37
[2022-11-10 22:49:25.874815] Train epoch [17/30], batch: 500/530, lr: 0.00039604, loss: 0.29298609, accuracy: 0.90830838, eta: 1:39:55
======================================================================
[2022-11-10 22:49:55.688918] Test 17, Accuracy: 0.8854166666666666
======================================================================
[2022-11-10 22:50:00.701249] Train epoch [18/30], batch: 0/530, lr: 0.00034549, loss: 0.22021246, accuracy: 0.93750000, eta: 8:27:41
[2022-11-10 22:51:35.124354] Train epoch [18/30], batch: 100/530, lr: 0.00034549, loss: 0.28055742, accuracy: 0.90160891, eta: 1:42:29
[2022-11-10 22:53:09.126551] Train epoch [18/30], batch: 200/530, lr: 0.00034549, loss: 0.27315825, accuracy: 0.90205224, eta: 1:38:41
[2022-11-10 22:54:42.665052] Train epoch [18/30], batch: 300/530, lr: 0.00034549, loss: 0.27104005, accuracy: 0.90365449, eta: 1:36:13
[2022-11-10 22:56:11.889257] Train epoch [18/30], batch: 400/530, lr: 0.00034549, loss: 0.27438635, accuracy: 0.90430175, eta: 1:33:07
[2022-11-10 22:57:45.554477] Train epoch [18/30], batch: 500/530, lr: 0.00034549, loss: 0.27314854, accuracy: 0.90668663, eta: 1:31:33
======================================================================
[2022-11-10 22:58:17.933452] Test 18, Accuracy: 0.8958333333333334
======================================================================
[2022-11-10 22:58:22.568589] Train epoch [19/30], batch: 0/530, lr: 0.00029663, loss: 0.16156010, accuracy: 1.00000000, eta: 7:08:39
[2022-11-10 22:59:55.363344] Train epoch [19/30], batch: 100/530, lr: 0.00029663, loss: 0.25462726, accuracy: 0.92388614, eta: 1:31:54
[2022-11-10 23:01:27.638808] Train epoch [19/30], batch: 200/530, lr: 0.00029663, loss: 0.22841427, accuracy: 0.93003731, eta: 1:28:27
[2022-11-10 23:02:59.649877] Train epoch [19/30], batch: 300/530, lr: 0.00029663, loss: 0.23628582, accuracy: 0.92504153, eta: 1:26:11
[2022-11-10 23:04:32.716400] Train epoch [19/30], batch: 400/530, lr: 0.00029663, loss: 0.24069692, accuracy: 0.92144638, eta: 1:24:31
[2022-11-10 23:06:05.493987] Train epoch [19/30], batch: 500/530, lr: 0.00029663, loss: 0.23726045, accuracy: 0.92290419, eta: 1:22:51
======================================================================
[2022-11-10 23:06:38.132990] Test 19, Accuracy: 0.9166666666666666
======================================================================
[2022-11-10 23:06:42.389483] Train epoch [20/30], batch: 0/530, lr: 0.00025000, loss: 0.51774669, accuracy: 0.81250000, eta: 5:57:10
[2022-11-10 23:08:14.888930] Train epoch [20/30], batch: 100/530, lr: 0.00025000, loss: 0.22179224, accuracy: 0.92698020, eta: 1:22:50
[2022-11-10 23:09:47.371756] Train epoch [20/30], batch: 200/530, lr: 0.00025000, loss: 0.24055548, accuracy: 0.92319652, eta: 1:19:56
[2022-11-10 23:11:19.943833] Train epoch [20/30], batch: 300/530, lr: 0.00025000, loss: 0.24179721, accuracy: 0.92421096, eta: 1:17:57
[2022-11-10 23:12:54.005460] Train epoch [20/30], batch: 400/530, lr: 0.00025000, loss: 0.23693213, accuracy: 0.92581047, eta: 1:16:30
[2022-11-10 23:14:29.588695] Train epoch [20/30], batch: 500/530, lr: 0.00025000, loss: 0.23493348, accuracy: 0.92577345, eta: 1:15:14
======================================================================
[2022-11-10 23:14:59.536399] Test 20, Accuracy: 0.8958333333333334
======================================================================
[2022-11-10 23:15:03.544243] Train epoch [21/30], batch: 0/530, lr: 0.00020611, loss: 0.02362767, accuracy: 1.00000000, eta: 4:57:52
[2022-11-10 23:16:34.772448] Train epoch [21/30], batch: 100/530, lr: 0.00020611, loss: 0.21170740, accuracy: 0.93564356, eta: 1:13:11
[2022-11-10 23:18:10.099058] Train epoch [21/30], batch: 200/530, lr: 0.00020611, loss: 0.22008163, accuracy: 0.92786070, eta: 1:12:06
[2022-11-10 23:19:41.833410] Train epoch [21/30], batch: 300/530, lr: 0.00020611, loss: 0.20972529, accuracy: 0.93127076, eta: 1:09:48
[2022-11-10 23:21:14.329119] Train epoch [21/30], batch: 400/530, lr: 0.00020611, loss: 0.21436511, accuracy: 0.92892768, eta: 1:08:01
[2022-11-10 23:22:47.614626] Train epoch [21/30], batch: 500/530, lr: 0.00020611, loss: 0.21442972, accuracy: 0.93001497, eta: 1:06:27
======================================================================
[2022-11-10 23:23:19.326635] Test 21, Accuracy: 0.9166666666666666
======================================================================
[2022-11-10 23:23:23.916726] Train epoch [22/30], batch: 0/530, lr: 0.00016543, loss: 0.14717999, accuracy: 0.93750000, eta: 5:08:24
[2022-11-10 23:24:55.750837] Train epoch [22/30], batch: 100/530, lr: 0.00016543, loss: 0.21177055, accuracy: 0.92636139, eta: 1:05:43
[2022-11-10 23:26:27.980494] Train epoch [22/30], batch: 200/530, lr: 0.00016543, loss: 0.20564176, accuracy: 0.93128109, eta: 1:03:07
[2022-11-10 23:28:02.730224] Train epoch [22/30], batch: 300/530, lr: 0.00016543, loss: 0.21154717, accuracy: 0.92774086, eta: 1:01:46
[2022-11-10 23:29:35.890358] Train epoch [22/30], batch: 400/530, lr: 0.00016543, loss: 0.20167984, accuracy: 0.93360349, eta: 1:00:03
[2022-11-10 23:31:07.752373] Train epoch [22/30], batch: 500/530, lr: 0.00016543, loss: 0.20074348, accuracy: 0.93275948, eta: 0:58:15
======================================================================
[2022-11-10 23:31:40.510352] Test 22, Accuracy: 0.9166666666666666
======================================================================
[2022-11-10 23:31:45.205304] Train epoch [23/30], batch: 0/530, lr: 0.00012843, loss: 0.12152800, accuracy: 0.93750000, eta: 4:35:58
[2022-11-10 23:33:16.933616] Train epoch [23/30], batch: 100/530, lr: 0.00012843, loss: 0.16801098, accuracy: 0.94678218, eta: 0:57:18
[2022-11-10 23:34:51.368944] Train epoch [23/30], batch: 200/530, lr: 0.00012843, loss: 0.19084118, accuracy: 0.94029851, eta: 0:55:28
[2022-11-10 23:36:22.178620] Train epoch [23/30], batch: 300/530, lr: 0.00012843, loss: 0.18425113, accuracy: 0.94082226, eta: 0:53:08
[2022-11-10 23:37:57.233694] Train epoch [23/30], batch: 400/530, lr: 0.00012843, loss: 0.18983552, accuracy: 0.93750000, eta: 0:51:47
[2022-11-10 23:39:27.288961] Train epoch [23/30], batch: 500/530, lr: 0.00012843, loss: 0.18675882, accuracy: 0.93887226, eta: 0:49:49
======================================================================
[2022-11-10 23:39:59.279859] Test 23, Accuracy: 0.9166666666666666
======================================================================
[2022-11-10 23:40:03.331253] Train epoch [24/30], batch: 0/530, lr: 0.00009549, loss: 0.08786958, accuracy: 0.93750000, eta: 3:22:56
[2022-11-10 23:41:37.077434] Train epoch [24/30], batch: 100/530, lr: 0.00009549, loss: 0.16405791, accuracy: 0.95111386, eta: 0:49:35
[2022-11-10 23:43:08.291247] Train epoch [24/30], batch: 200/530, lr: 0.00009549, loss: 0.16266945, accuracy: 0.94931592, eta: 0:46:38
[2022-11-10 23:44:40.110493] Train epoch [24/30], batch: 300/530, lr: 0.00009549, loss: 0.16532327, accuracy: 0.94725914, eta: 0:44:44
[2022-11-10 23:46:13.857100] Train epoch [24/30], batch: 400/530, lr: 0.00009549, loss: 0.16139467, accuracy: 0.94872195, eta: 0:43:15
[2022-11-10 23:47:46.241240] Train epoch [24/30], batch: 500/530, lr: 0.00009549, loss: 0.16513310, accuracy: 0.94660679, eta: 0:41:36
======================================================================
[2022-11-10 23:48:18.758348] Test 24, Accuracy: 0.9166666666666666
======================================================================
[2022-11-10 23:48:22.866720] Train epoch [25/30], batch: 0/530, lr: 0.00006699, loss: 0.07195831, accuracy: 1.00000000, eta: 2:51:44
[2022-11-10 23:49:58.617136] Train epoch [25/30], batch: 100/530, lr: 0.00006699, loss: 0.13115495, accuracy: 0.96225248, eta: 0:41:55
[2022-11-10 23:51:28.921034] Train epoch [25/30], batch: 200/530, lr: 0.00006699, loss: 0.13909703, accuracy: 0.96019900, eta: 0:38:35
[2022-11-10 23:53:01.271986] Train epoch [25/30], batch: 300/530, lr: 0.00006699, loss: 0.14324175, accuracy: 0.95847176, eta: 0:36:43
[2022-11-10 23:54:32.966929] Train epoch [25/30], batch: 400/530, lr: 0.00006699, loss: 0.14921372, accuracy: 0.95604738, eta: 0:34:58
[2022-11-10 23:56:06.998757] Train epoch [25/30], batch: 500/530, lr: 0.00006699, loss: 0.15173155, accuracy: 0.95533932, eta: 0:33:28
======================================================================
[2022-11-10 23:56:38.951939] Test 25, Accuracy: 0.9479166666666666
======================================================================
[2022-11-10 23:56:43.358150] Train epoch [26/30], batch: 0/530, lr: 0.00004323, loss: 0.60216975, accuracy: 0.87500000, eta: 2:28:13
[2022-11-10 23:58:16.831394] Train epoch [26/30], batch: 100/530, lr: 0.00004323, loss: 0.17103851, accuracy: 0.94306931, eta: 0:32:33
[2022-11-10 23:59:51.982402] Train epoch [26/30], batch: 200/530, lr: 0.00004323, loss: 0.15951316, accuracy: 0.94962687, eta: 0:30:41
[2022-11-11 00:01:21.717387] Train epoch [26/30], batch: 300/530, lr: 0.00004323, loss: 0.15574858, accuracy: 0.95141196, eta: 0:28:28
[2022-11-11 00:02:54.439065] Train epoch [26/30], batch: 400/530, lr: 0.00004323, loss: 0.15034777, accuracy: 0.95168329, eta: 0:26:49
[2022-11-11 00:04:25.981497] Train epoch [26/30], batch: 500/530, lr: 0.00004323, loss: 0.14729071, accuracy: 0.95384232, eta: 0:25:09
======================================================================
[2022-11-11 00:04:57.566501] Test 26, Accuracy: 0.9166666666666666
======================================================================
[2022-11-11 00:05:01.615790] Train epoch [27/30], batch: 0/530, lr: 0.00002447, loss: 0.17865732, accuracy: 0.93750000, eta: 1:41:15
[2022-11-11 00:06:34.693229] Train epoch [27/30], batch: 100/530, lr: 0.00002447, loss: 0.15059978, accuracy: 0.95297030, eta: 0:23:49
[2022-11-11 00:08:06.900903] Train epoch [27/30], batch: 200/530, lr: 0.00002447, loss: 0.14999241, accuracy: 0.95398010, eta: 0:21:47
[2022-11-11 00:09:41.431182] Train epoch [27/30], batch: 300/530, lr: 0.00002447, loss: 0.14569680, accuracy: 0.95411130, eta: 0:20:15
[2022-11-11 00:11:12.423135] Train epoch [27/30], batch: 400/530, lr: 0.00002447, loss: 0.14180268, accuracy: 0.95511222, eta: 0:18:31
[2022-11-11 00:12:46.743488] Train epoch [27/30], batch: 500/530, lr: 0.00002447, loss: 0.14129741, accuracy: 0.95583832, eta: 0:17:00
======================================================================
[2022-11-11 00:13:18.663446] Test 27, Accuracy: 0.90625
======================================================================
[2022-11-11 00:13:23.405206] Train epoch [28/30], batch: 0/530, lr: 0.00001093, loss: 0.12205333, accuracy: 0.93750000, eta: 1:19:53
[2022-11-11 00:14:56.676071] Train epoch [28/30], batch: 100/530, lr: 0.00001093, loss: 0.14063962, accuracy: 0.95606436, eta: 0:15:29
[2022-11-11 00:16:31.698910] Train epoch [28/30], batch: 200/530, lr: 0.00001093, loss: 0.14116849, accuracy: 0.95646766, eta: 0:13:44
[2022-11-11 00:18:04.578784] Train epoch [28/30], batch: 300/530, lr: 0.00001093, loss: 0.13765486, accuracy: 0.95639535, eta: 0:12:01
[2022-11-11 00:19:37.015601] Train epoch [28/30], batch: 400/530, lr: 0.00001093, loss: 0.13231906, accuracy: 0.95791771, eta: 0:10:22
[2022-11-11 00:21:12.200799] Train epoch [28/30], batch: 500/530, lr: 0.00001093, loss: 0.13558556, accuracy: 0.95683633, eta: 0:08:49
======================================================================
[2022-11-11 00:21:42.086452] Test 28, Accuracy: 0.9270833333333334
======================================================================
[2022-11-11 00:21:46.403711] Train epoch [29/30], batch: 0/530, lr: 0.00000274, loss: 0.02429851, accuracy: 1.00000000, eta: 0:35:59
[2022-11-11 00:23:18.801914] Train epoch [29/30], batch: 100/530, lr: 0.00000274, loss: 0.13516679, accuracy: 0.95977723, eta: 0:06:50
[2022-11-11 00:24:52.401667] Train epoch [29/30], batch: 200/530, lr: 0.00000274, loss: 0.14442922, accuracy: 0.95304726, eta: 0:05:12
[2022-11-11 00:26:26.847263] Train epoch [29/30], batch: 300/530, lr: 0.00000274, loss: 0.14353442, accuracy: 0.95328073, eta: 0:03:37
[2022-11-11 00:27:58.826081] Train epoch [29/30], batch: 400/530, lr: 0.00000274, loss: 0.13701868, accuracy: 0.95729426, eta: 0:02:02
[2022-11-11 00:29:32.349156] Train epoch [29/30], batch: 500/530, lr: 0.00000274, loss: 0.13608442, accuracy: 0.95733533, eta: 0:00:28
======================================================================
[2022-11-11 00:30:02.840534] Test 29, Accuracy: 0.9270833333333334
======================================================================

进程已结束,退出代码0