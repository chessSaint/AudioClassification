D:\ProgramData\Anaconda3\envs\audio\python.exe E:/postgraduate/research/…˘“Ù∑÷¿‡/AudioClassification-Pytorch/train.py
-----------  Configuration Arguments -----------
audio_duration: 3
augment_conf_path: configs/augment.yml
batch_size: 16
feature_method: melspectrogram
learning_rate: 0.001
min_duration: 0.5
num_classes: 10
num_epoch: 30
num_workers: 4
resume: None
save_model_dir: output/models/
test_list_path: dataset/test_list.txt
train_list_path: dataset/train_list.txt
use_model: ecapa_tdnn
------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 512, 98]         204,800
       BatchNorm1d-2              [-1, 512, 98]           1,024
      Conv1dReluBn-3              [-1, 512, 98]               0
            Conv1d-4              [-1, 512, 98]         262,144
       BatchNorm1d-5              [-1, 512, 98]           1,024
      Conv1dReluBn-6              [-1, 512, 98]               0
            Conv1d-7               [-1, 64, 98]          12,288
       BatchNorm1d-8               [-1, 64, 98]             128
            Conv1d-9               [-1, 64, 98]          12,288
      BatchNorm1d-10               [-1, 64, 98]             128
           Conv1d-11               [-1, 64, 98]          12,288
      BatchNorm1d-12               [-1, 64, 98]             128
           Conv1d-13               [-1, 64, 98]          12,288
      BatchNorm1d-14               [-1, 64, 98]             128
           Conv1d-15               [-1, 64, 98]          12,288
      BatchNorm1d-16               [-1, 64, 98]             128
           Conv1d-17               [-1, 64, 98]          12,288
      BatchNorm1d-18               [-1, 64, 98]             128
           Conv1d-19               [-1, 64, 98]          12,288
      BatchNorm1d-20               [-1, 64, 98]             128
 Res2Conv1dReluBn-21              [-1, 512, 98]               0
           Conv1d-22              [-1, 512, 98]         262,144
      BatchNorm1d-23              [-1, 512, 98]           1,024
     Conv1dReluBn-24              [-1, 512, 98]               0
           Linear-25                  [-1, 256]         131,328
           Linear-26                  [-1, 512]         131,584
       SE_Connect-27              [-1, 512, 98]               0
           Conv1d-28              [-1, 512, 98]         262,144
      BatchNorm1d-29              [-1, 512, 98]           1,024
     Conv1dReluBn-30              [-1, 512, 98]               0
           Conv1d-31               [-1, 64, 98]          12,288
      BatchNorm1d-32               [-1, 64, 98]             128
           Conv1d-33               [-1, 64, 98]          12,288
      BatchNorm1d-34               [-1, 64, 98]             128
           Conv1d-35               [-1, 64, 98]          12,288
      BatchNorm1d-36               [-1, 64, 98]             128
           Conv1d-37               [-1, 64, 98]          12,288
      BatchNorm1d-38               [-1, 64, 98]             128
           Conv1d-39               [-1, 64, 98]          12,288
      BatchNorm1d-40               [-1, 64, 98]             128
           Conv1d-41               [-1, 64, 98]          12,288
      BatchNorm1d-42               [-1, 64, 98]             128
           Conv1d-43               [-1, 64, 98]          12,288
      BatchNorm1d-44               [-1, 64, 98]             128
 Res2Conv1dReluBn-45              [-1, 512, 98]               0
           Conv1d-46              [-1, 512, 98]         262,144
      BatchNorm1d-47              [-1, 512, 98]           1,024
     Conv1dReluBn-48              [-1, 512, 98]               0
           Linear-49                  [-1, 256]         131,328
           Linear-50                  [-1, 512]         131,584
       SE_Connect-51              [-1, 512, 98]               0
           Conv1d-52              [-1, 512, 98]         262,144
      BatchNorm1d-53              [-1, 512, 98]           1,024
     Conv1dReluBn-54              [-1, 512, 98]               0
           Conv1d-55               [-1, 64, 98]          12,288
      BatchNorm1d-56               [-1, 64, 98]             128
           Conv1d-57               [-1, 64, 98]          12,288
      BatchNorm1d-58               [-1, 64, 98]             128
           Conv1d-59               [-1, 64, 98]          12,288
      BatchNorm1d-60               [-1, 64, 98]             128
           Conv1d-61               [-1, 64, 98]          12,288
      BatchNorm1d-62               [-1, 64, 98]             128
           Conv1d-63               [-1, 64, 98]          12,288
      BatchNorm1d-64               [-1, 64, 98]             128
           Conv1d-65               [-1, 64, 98]          12,288
      BatchNorm1d-66               [-1, 64, 98]             128
           Conv1d-67               [-1, 64, 98]          12,288
      BatchNorm1d-68               [-1, 64, 98]             128
 Res2Conv1dReluBn-69              [-1, 512, 98]               0
           Conv1d-70              [-1, 512, 98]         262,144
      BatchNorm1d-71              [-1, 512, 98]           1,024
     Conv1dReluBn-72              [-1, 512, 98]               0
           Linear-73                  [-1, 256]         131,328
           Linear-74                  [-1, 512]         131,584
       SE_Connect-75              [-1, 512, 98]               0
           Conv1d-76             [-1, 1536, 98]       2,360,832
           Conv1d-77              [-1, 128, 98]         196,736
           Conv1d-78             [-1, 1536, 98]         198,144
AttentiveStatsPool-79                 [-1, 3072]               0
      BatchNorm1d-80                 [-1, 3072]           6,144
           Linear-81                  [-1, 192]         590,016
      BatchNorm1d-82                  [-1, 192]             384
           Linear-83                   [-1, 10]           1,930
================================================================
Total params: 6,188,490
Trainable params: 6,188,490
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.03
Forward/backward pass size (MB): 14.81
Params size (MB): 23.61
Estimated Total Size (MB): 38.44
----------------------------------------------------------------
[2022-11-06 10:01:40.149257] Train epoch [0/30], batch: 0/530, lr: 0.00100000, loss: 2.56492710, accuracy: 0.00000000, eta: 3 days, 15:18:32
[2022-11-06 10:04:08.710896] Train epoch [0/30], batch: 100/530, lr: 0.00100000, loss: 1.71318185, accuracy: 0.42759901, eta: 7:18:39
[2022-11-06 10:06:32.791512] Train epoch [0/30], batch: 200/530, lr: 0.00100000, loss: 1.56282878, accuracy: 0.48351990, eta: 6:46:35
[2022-11-06 10:08:50.948973] Train epoch [0/30], batch: 300/530, lr: 0.00100000, loss: 1.47801661, accuracy: 0.50768272, eta: 6:29:07
[2022-11-06 10:11:09.030636] Train epoch [0/30], batch: 400/530, lr: 0.00100000, loss: 1.41604257, accuracy: 0.52649626, eta: 6:19:09
[2022-11-06 10:13:28.407836] Train epoch [0/30], batch: 500/530, lr: 0.00100000, loss: 1.36493826, accuracy: 0.54578343, eta: 6:12:55
======================================================================
[2022-11-06 10:14:28.878440] Test 0, Accuracy: 0.7395833333333334
======================================================================
[2022-11-06 10:14:45.686483] Train epoch [1/30], batch: 0/530, lr: 0.00099726, loss: 0.91612971, accuracy: 0.81250000, eta: 2 days, 21:55:47
[2022-11-06 10:16:49.134289] Train epoch [1/30], batch: 100/530, lr: 0.00099726, loss: 1.05864871, accuracy: 0.64913366, eta: 5:52:19
[2022-11-06 10:18:55.434464] Train epoch [1/30], batch: 200/530, lr: 0.00099726, loss: 1.07768655, accuracy: 0.64614428, eta: 5:34:45
[2022-11-06 10:21:01.444418] Train epoch [1/30], batch: 300/530, lr: 0.00099726, loss: 1.06654608, accuracy: 0.64597176, eta: 5:27:12
[2022-11-06 10:23:09.930747] Train epoch [1/30], batch: 400/530, lr: 0.00099726, loss: 1.06888795, accuracy: 0.64370324, eta: 5:23:55
[2022-11-06 10:25:25.101195] Train epoch [1/30], batch: 500/530, lr: 0.00099726, loss: 1.06638622, accuracy: 0.64533433, eta: 5:24:23
======================================================================
[2022-11-06 10:26:27.242292] Test 1, Accuracy: 0.7291666666666666
======================================================================
[2022-11-06 10:26:43.300340] Train epoch [2/30], batch: 0/530, lr: 0.00098907, loss: 1.02444100, accuracy: 0.75000000, eta: 2 days, 16:49:17
[2022-11-06 10:28:45.787715] Train epoch [2/30], batch: 100/530, lr: 0.00098907, loss: 0.95939887, accuracy: 0.68502475, eta: 5:36:10
[2022-11-06 10:30:51.146409] Train epoch [2/30], batch: 200/530, lr: 0.00098907, loss: 0.95855612, accuracy: 0.68563433, eta: 5:19:57
[2022-11-06 10:32:54.430653] Train epoch [2/30], batch: 300/530, lr: 0.00098907, loss: 0.96029496, accuracy: 0.68355482, eta: 5:11:26
[2022-11-06 10:34:59.215880] Train epoch [2/30], batch: 400/530, lr: 0.00098907, loss: 0.94981223, accuracy: 0.68781172, eta: 5:07:03
[2022-11-06 10:37:15.091445] Train epoch [2/30], batch: 500/530, lr: 0.00098907, loss: 0.94938278, accuracy: 0.68650200, eta: 5:08:52
======================================================================
[2022-11-06 10:38:18.286265] Test 2, Accuracy: 0.6770833333333334
======================================================================
[2022-11-06 10:38:33.998268] Train epoch [3/30], batch: 0/530, lr: 0.00097553, loss: 1.98885942, accuracy: 0.31250000, eta: 2 days, 12:57:52
[2022-11-06 10:40:36.689098] Train epoch [3/30], batch: 100/530, lr: 0.00097553, loss: 0.87067276, accuracy: 0.72215347, eta: 5:23:39
[2022-11-06 10:42:44.118842] Train epoch [3/30], batch: 200/530, lr: 0.00097553, loss: 0.85711390, accuracy: 0.72139303, eta: 5:10:34
[2022-11-06 10:44:56.454871] Train epoch [3/30], batch: 300/530, lr: 0.00097553, loss: 0.87878579, accuracy: 0.71158638, eta: 5:08:34
[2022-11-06 10:47:08.108728] Train epoch [3/30], batch: 400/530, lr: 0.00097553, loss: 0.87797529, accuracy: 0.71228180, eta: 5:06:05
[2022-11-06 10:49:26.744027] Train epoch [3/30], batch: 500/530, lr: 0.00097553, loss: 0.88000166, accuracy: 0.71020459, eta: 5:06:55
======================================================================
[2022-11-06 10:50:29.771387] Test 3, Accuracy: 0.7743055555555555
======================================================================
[2022-11-06 10:50:45.291876] Train epoch [4/30], batch: 0/530, lr: 0.00095677, loss: 0.57196188, accuracy: 0.81250000, eta: 2 days, 10:22:41
[2022-11-06 10:52:49.114676] Train epoch [4/30], batch: 100/530, lr: 0.00095677, loss: 0.83923322, accuracy: 0.73762376, eta: 5:13:56
[2022-11-06 10:54:56.120963] Train epoch [4/30], batch: 200/530, lr: 0.00095677, loss: 0.82201231, accuracy: 0.74284826, eta: 4:59:36
[2022-11-06 10:57:02.011239] Train epoch [4/30], batch: 300/530, lr: 0.00095677, loss: 0.82030600, accuracy: 0.73297342, eta: 4:52:33
[2022-11-06 10:59:05.032184] Train epoch [4/30], batch: 400/530, lr: 0.00095677, loss: 0.79531139, accuracy: 0.74127182, eta: 4:46:23
[2022-11-06 11:01:18.775453] Train epoch [4/30], batch: 500/530, lr: 0.00095677, loss: 0.79989386, accuracy: 0.73839820, eta: 4:46:35
======================================================================
[2022-11-06 11:02:25.242844] Test 4, Accuracy: 0.8125
======================================================================
[2022-11-06 11:02:41.513325] Train epoch [5/30], batch: 0/530, lr: 0.00093301, loss: 0.68781030, accuracy: 0.75000000, eta: 2 days, 10:55:21
[2022-11-06 11:04:46.416240] Train epoch [5/30], batch: 100/530, lr: 0.00093301, loss: 0.80018795, accuracy: 0.72834158, eta: 5:05:46
[2022-11-06 11:06:54.871649] Train epoch [5/30], batch: 200/530, lr: 0.00093301, loss: 0.76047289, accuracy: 0.74937811, eta: 4:51:28
[2022-11-06 11:08:56.998990] Train epoch [5/30], batch: 300/530, lr: 0.00093301, loss: 0.74481237, accuracy: 0.75373754, eta: 4:40:43
[2022-11-06 11:11:04.011257] Train epoch [5/30], batch: 400/530, lr: 0.00093301, loss: 0.73345536, accuracy: 0.75748130, eta: 4:36:55
[2022-11-06 11:13:19.887819] Train epoch [5/30], batch: 500/530, lr: 0.00093301, loss: 0.74088603, accuracy: 0.75199601, eta: 4:37:33
======================================================================
[2022-11-06 11:14:24.013406] Test 5, Accuracy: 0.84375
======================================================================
[2022-11-06 11:14:41.028895] Train epoch [6/30], batch: 0/530, lr: 0.00090451, loss: 0.42218268, accuracy: 0.93750000, eta: 2 days, 11:10:24
[2022-11-06 11:16:44.680156] Train epoch [6/30], batch: 100/530, lr: 0.00090451, loss: 0.69047165, accuracy: 0.77227723, eta: 4:52:22
[2022-11-06 11:18:49.634930] Train epoch [6/30], batch: 200/530, lr: 0.00090451, loss: 0.71619612, accuracy: 0.76958955, eta: 4:35:28
[2022-11-06 11:20:53.491644] Train epoch [6/30], batch: 300/530, lr: 0.00090451, loss: 0.71403146, accuracy: 0.76806478, eta: 4:27:39
[2022-11-06 11:23:02.658151] Train epoch [6/30], batch: 400/530, lr: 0.00090451, loss: 0.70966727, accuracy: 0.76652120, eta: 4:25:25
[2022-11-06 11:25:15.140791] Train epoch [6/30], batch: 500/530, lr: 0.00090451, loss: 0.70563799, accuracy: 0.76833832, eta: 4:24:34
======================================================================
[2022-11-06 11:26:22.118131] Test 6, Accuracy: 0.875
======================================================================
[2022-11-06 11:26:39.411876] Train epoch [7/30], batch: 0/530, lr: 0.00087157, loss: 0.53091198, accuracy: 0.81250000, eta: 2 days, 9:37:59
[2022-11-06 11:28:49.725317] Train epoch [7/30], batch: 100/530, lr: 0.00087157, loss: 0.64193398, accuracy: 0.79826733, eta: 4:53:56
[2022-11-06 11:30:49.586714] Train epoch [7/30], batch: 200/530, lr: 0.00087157, loss: 0.63828468, accuracy: 0.79601990, eta: 4:25:38
[2022-11-06 11:32:56.949049] Train epoch [7/30], batch: 300/530, lr: 0.00087157, loss: 0.65436679, accuracy: 0.78529900, eta: 4:19:45
[2022-11-06 11:35:01.814065] Train epoch [7/30], batch: 400/530, lr: 0.00087157, loss: 0.65140593, accuracy: 0.78631546, eta: 4:14:31
[2022-11-06 11:37:17.016179] Train epoch [7/30], batch: 500/530, lr: 0.00087157, loss: 0.64505631, accuracy: 0.78854790, eta: 4:14:34
======================================================================
[2022-11-06 11:38:19.767286] Test 7, Accuracy: 0.8333333333333334
======================================================================
[2022-11-06 11:38:37.035100] Train epoch [8/30], batch: 0/530, lr: 0.00083457, loss: 0.50035352, accuracy: 0.81250000, eta: 2 days, 6:46:07
[2022-11-06 11:40:49.259429] Train epoch [8/30], batch: 100/530, lr: 0.00083457, loss: 0.55053961, accuracy: 0.81250000, eta: 4:44:29
[2022-11-06 11:42:55.782012] Train epoch [8/30], batch: 200/530, lr: 0.00083457, loss: 0.58106178, accuracy: 0.80441542, eta: 4:21:56
[2022-11-06 11:44:59.209870] Train epoch [8/30], batch: 300/530, lr: 0.00083457, loss: 0.59244287, accuracy: 0.80191030, eta: 4:11:01
[2022-11-06 11:47:08.956826] Train epoch [8/30], batch: 400/530, lr: 0.00083457, loss: 0.59656549, accuracy: 0.80221322, eta: 4:07:29
[2022-11-06 11:49:28.502573] Train epoch [8/30], batch: 500/530, lr: 0.00083457, loss: 0.59420002, accuracy: 0.80114770, eta: 4:08:08
======================================================================
[2022-11-06 11:50:27.743056] Test 8, Accuracy: 0.8541666666666666
======================================================================
[2022-11-06 11:50:45.404856] Train epoch [9/30], batch: 0/530, lr: 0.00079389, loss: 0.63217235, accuracy: 0.87500000, eta: 2 days, 5:47:36
[2022-11-06 11:52:46.568768] Train epoch [9/30], batch: 100/530, lr: 0.00079389, loss: 0.55644411, accuracy: 0.81930693, eta: 4:12:12
[2022-11-06 11:54:56.261871] Train epoch [9/30], batch: 200/530, lr: 0.00079389, loss: 0.57257092, accuracy: 0.81498756, eta: 4:03:06
[2022-11-06 11:57:04.452990] Train epoch [9/30], batch: 300/530, lr: 0.00079389, loss: 0.57854539, accuracy: 0.81270764, eta: 3:57:43
[2022-11-06 11:59:15.225203] Train epoch [9/30], batch: 400/530, lr: 0.00079389, loss: 0.58024883, accuracy: 0.80907107, eta: 3:55:06
[2022-11-06 12:01:24.439584] Train epoch [9/30], batch: 500/530, lr: 0.00079389, loss: 0.56973565, accuracy: 0.81274950, eta: 3:52:07
======================================================================
[2022-11-06 12:02:31.367771] Test 9, Accuracy: 0.8645833333333334
======================================================================
[2022-11-06 12:02:47.130610] Train epoch [10/30], batch: 0/530, lr: 0.00075000, loss: 0.69876826, accuracy: 0.68750000, eta: 1 day, 21:38:04
[2022-11-06 12:04:50.334070] Train epoch [10/30], batch: 100/530, lr: 0.00075000, loss: 0.51746517, accuracy: 0.82240099, eta: 4:00:19
[2022-11-06 12:06:53.715053] Train epoch [10/30], batch: 200/530, lr: 0.00075000, loss: 0.53040582, accuracy: 0.82182836, eta: 3:46:00
[2022-11-06 12:09:00.318417] Train epoch [10/30], batch: 300/530, lr: 0.00075000, loss: 0.52953470, accuracy: 0.82184385, eta: 3:41:40
[2022-11-06 12:11:05.111629] Train epoch [10/30], batch: 400/530, lr: 0.00075000, loss: 0.52495289, accuracy: 0.82278678, eta: 3:37:40
[2022-11-06 12:13:14.223279] Train epoch [10/30], batch: 500/530, lr: 0.00075000, loss: 0.52289063, accuracy: 0.82422655, eta: 3:35:54
======================================================================
[2022-11-06 12:14:14.647498] Test 10, Accuracy: 0.8541666666666666
======================================================================
[2022-11-06 12:14:30.924960] Train epoch [11/30], batch: 0/530, lr: 0.00070337, loss: 0.31778538, accuracy: 0.93750000, eta: 1 day, 20:46:52
[2022-11-06 12:16:34.489454] Train epoch [11/30], batch: 100/530, lr: 0.00070337, loss: 0.45446309, accuracy: 0.85148515, eta: 3:49:37
[2022-11-06 12:18:39.293633] Train epoch [11/30], batch: 200/530, lr: 0.00070337, loss: 0.45562896, accuracy: 0.85230100, eta: 3:36:22
[2022-11-06 12:20:43.289968] Train epoch [11/30], batch: 300/530, lr: 0.00070337, loss: 0.48241603, accuracy: 0.84219269, eta: 3:30:05
[2022-11-06 12:22:47.555591] Train epoch [11/30], batch: 400/530, lr: 0.00070337, loss: 0.48304141, accuracy: 0.84071072, eta: 3:26:01
[2022-11-06 12:24:54.895981] Train epoch [11/30], batch: 500/530, lr: 0.00070337, loss: 0.48316106, accuracy: 0.84081836, eta: 3:23:44
======================================================================
[2022-11-06 12:26:00.492243] Test 11, Accuracy: 0.8541666666666666
======================================================================
[2022-11-06 12:26:17.596494] Train epoch [12/30], batch: 0/530, lr: 0.00065451, loss: 0.21440133, accuracy: 0.93750000, eta: 1 day, 20:35:39
[2022-11-06 12:28:22.884377] Train epoch [12/30], batch: 100/530, lr: 0.00065451, loss: 0.43349701, accuracy: 0.85210396, eta: 3:41:22
[2022-11-06 12:30:25.657985] Train epoch [12/30], batch: 200/530, lr: 0.00065451, loss: 0.45202571, accuracy: 0.85167910, eta: 3:25:08
[2022-11-06 12:32:34.209141] Train epoch [12/30], batch: 300/530, lr: 0.00065451, loss: 0.46828410, accuracy: 0.84696844, eta: 3:21:17
[2022-11-06 12:34:42.314488] Train epoch [12/30], batch: 400/530, lr: 0.00065451, loss: 0.45728216, accuracy: 0.84928304, eta: 3:18:07
[2022-11-06 12:36:54.061097] Train epoch [12/30], batch: 500/530, lr: 0.00065451, loss: 0.46844977, accuracy: 0.84643214, eta: 3:16:27
======================================================================
[2022-11-06 12:37:59.021637] Test 12, Accuracy: 0.90625
======================================================================
[2022-11-06 12:38:14.825367] Train epoch [13/30], batch: 0/530, lr: 0.00060396, loss: 0.46596926, accuracy: 0.87500000, eta: 1 day, 14:53:30
[2022-11-06 12:40:20.267837] Train epoch [13/30], batch: 100/530, lr: 0.00060396, loss: 0.38722157, accuracy: 0.87314356, eta: 3:27:17
[2022-11-06 12:42:25.296418] Train epoch [13/30], batch: 200/530, lr: 0.00060396, loss: 0.42602873, accuracy: 0.85945274, eta: 3:14:19
[2022-11-06 12:44:31.595593] Train epoch [13/30], batch: 300/530, lr: 0.00060396, loss: 0.43186817, accuracy: 0.85672757, eta: 3:09:11
[2022-11-06 12:46:35.242868] Train epoch [13/30], batch: 400/530, lr: 0.00060396, loss: 0.43656534, accuracy: 0.85520574, eta: 3:04:37
[2022-11-06 12:48:47.941925] Train epoch [13/30], batch: 500/530, lr: 0.00060396, loss: 0.42881262, accuracy: 0.85778443, eta: 3:03:37
======================================================================
[2022-11-06 12:49:52.042724] Test 13, Accuracy: 0.8645833333333334
======================================================================
[2022-11-06 12:50:08.210480] Train epoch [14/30], batch: 0/530, lr: 0.00055226, loss: 0.29216462, accuracy: 0.93750000, eta: 1 day, 13:29:22
[2022-11-06 12:52:12.479097] Train epoch [14/30], batch: 100/530, lr: 0.00055226, loss: 0.38054574, accuracy: 0.87995050, eta: 3:13:51
[2022-11-06 12:54:17.968437] Train epoch [14/30], batch: 200/530, lr: 0.00055226, loss: 0.37670752, accuracy: 0.88152985, eta: 3:02:23
[2022-11-06 12:56:23.066824] Train epoch [14/30], batch: 300/530, lr: 0.00055226, loss: 0.38122877, accuracy: 0.87811462, eta: 2:56:59
[2022-11-06 12:58:31.494310] Train epoch [14/30], batch: 400/530, lr: 0.00055226, loss: 0.38387701, accuracy: 0.87811721, eta: 2:54:21
[2022-11-06 13:00:38.414827] Train epoch [14/30], batch: 500/530, lr: 0.00055226, loss: 0.38596231, accuracy: 0.87699601, eta: 2:51:31
======================================================================
[2022-11-06 13:01:40.350601] Test 14, Accuracy: 0.8854166666666666
======================================================================
[2022-11-06 13:01:56.603165] Train epoch [15/30], batch: 0/530, lr: 0.00050000, loss: 0.43472856, accuracy: 0.81250000, eta: 1 day, 11:18:42
[2022-11-06 13:04:05.219149] Train epoch [15/30], batch: 100/530, lr: 0.00050000, loss: 0.33980346, accuracy: 0.89418317, eta: 3:07:19
[2022-11-06 13:06:08.668949] Train epoch [15/30], batch: 200/530, lr: 0.00050000, loss: 0.34051284, accuracy: 0.89148010, eta: 2:52:15
[2022-11-06 13:08:13.248728] Train epoch [15/30], batch: 300/530, lr: 0.00050000, loss: 0.33392733, accuracy: 0.89493355, eta: 2:46:18
[2022-11-06 13:10:22.004335] Train epoch [15/30], batch: 400/530, lr: 0.00050000, loss: 0.34667948, accuracy: 0.89027431, eta: 2:43:36
[2022-11-06 13:12:28.439150] Train epoch [15/30], batch: 500/530, lr: 0.00050000, loss: 0.35018206, accuracy: 0.88747505, eta: 2:40:33
======================================================================
[2022-11-06 13:13:34.981673] Test 15, Accuracy: 0.9479166666666666
======================================================================
[2022-11-06 13:13:51.694969] Train epoch [16/30], batch: 0/530, lr: 0.00044774, loss: 0.06449700, accuracy: 1.00000000, eta: 1 day, 9:55:40
[2022-11-06 13:16:02.683606] Train epoch [16/30], batch: 100/530, lr: 0.00044774, loss: 0.27235022, accuracy: 0.91089109, eta: 2:58:06
[2022-11-06 13:18:15.694830] Train epoch [16/30], batch: 200/530, lr: 0.00044774, loss: 0.29428628, accuracy: 0.90298507, eta: 2:47:54
[2022-11-06 13:20:18.547228] Train epoch [16/30], batch: 300/530, lr: 0.00044774, loss: 0.32083708, accuracy: 0.89472591, eta: 2:39:00
[2022-11-06 13:22:24.886310] Train epoch [16/30], batch: 400/530, lr: 0.00044774, loss: 0.32905063, accuracy: 0.89011845, eta: 2:34:32
[2022-11-06 13:24:30.931159] Train epoch [16/30], batch: 500/530, lr: 0.00044774, loss: 0.33653200, accuracy: 0.88784930, eta: 2:30:56
======================================================================
[2022-11-06 13:25:32.089721] Test 16, Accuracy: 0.9375
======================================================================
[2022-11-06 13:25:48.505841] Train epoch [17/30], batch: 0/530, lr: 0.00039604, loss: 0.32348070, accuracy: 0.87500000, eta: 1 day, 6:54:25
[2022-11-06 13:27:52.848254] Train epoch [17/30], batch: 100/530, lr: 0.00039604, loss: 0.26369441, accuracy: 0.91150990, eta: 2:37:24
[2022-11-06 13:29:55.624855] Train epoch [17/30], batch: 200/530, lr: 0.00039604, loss: 0.28840700, accuracy: 0.90764925, eta: 2:26:02
[2022-11-06 13:32:00.264473] Train epoch [17/30], batch: 300/530, lr: 0.00039604, loss: 0.29999909, accuracy: 0.90303156, eta: 2:21:32
[2022-11-06 13:34:00.236575] Train epoch [17/30], batch: 400/530, lr: 0.00039604, loss: 0.30640334, accuracy: 0.89884663, eta: 2:16:59
[2022-11-06 13:36:07.963932] Train epoch [17/30], batch: 500/530, lr: 0.00039604, loss: 0.31148723, accuracy: 0.89782934, eta: 2:15:06
======================================================================
[2022-11-06 13:36:57.559307] Test 17, Accuracy: 0.9166666666666666
======================================================================
[2022-11-06 13:37:14.540206] Train epoch [18/30], batch: 0/530, lr: 0.00034549, loss: 0.14732881, accuracy: 1.00000000, eta: 1 day, 5:31:19
[2022-11-06 13:39:18.261284] Train epoch [18/30], batch: 100/530, lr: 0.00034549, loss: 0.25437805, accuracy: 0.92636139, eta: 2:25:03
[2022-11-06 13:41:22.563799] Train epoch [18/30], batch: 200/530, lr: 0.00034549, loss: 0.26936528, accuracy: 0.91635572, eta: 2:15:13
[2022-11-06 13:43:28.119965] Train epoch [18/30], batch: 300/530, lr: 0.00034549, loss: 0.28047705, accuracy: 0.91050664, eta: 2:10:57
[2022-11-06 13:45:31.515910] Train epoch [18/30], batch: 400/530, lr: 0.00034549, loss: 0.28289783, accuracy: 0.91038030, eta: 2:07:14
[2022-11-06 13:47:35.586051] Train epoch [18/30], batch: 500/530, lr: 0.00034549, loss: 0.28057522, accuracy: 0.91042914, eta: 2:04:19
======================================================================
[2022-11-06 13:48:20.838011] Test 18, Accuracy: 0.9375
======================================================================
[2022-11-06 13:48:37.415792] Train epoch [19/30], batch: 0/530, lr: 0.00029663, loss: 0.45651224, accuracy: 0.87500000, eta: 1 day, 2:25:07
[2022-11-06 13:50:45.418415] Train epoch [19/30], batch: 100/530, lr: 0.00029663, loss: 0.23892315, accuracy: 0.92202970, eta: 2:16:27
[2022-11-06 13:52:48.505186] Train epoch [19/30], batch: 200/530, lr: 0.00029663, loss: 0.24371825, accuracy: 0.92133085, eta: 2:04:49
[2022-11-06 13:54:51.313702] Train epoch [19/30], batch: 300/530, lr: 0.00029663, loss: 0.24877353, accuracy: 0.92109635, eta: 1:59:28
[2022-11-06 13:56:59.183682] Train epoch [19/30], batch: 400/530, lr: 0.00029663, loss: 0.24747136, accuracy: 0.92082294, eta: 1:56:55
[2022-11-06 13:58:59.186697] Train epoch [19/30], batch: 500/530, lr: 0.00029663, loss: 0.24677208, accuracy: 0.92178144, eta: 1:53:08
======================================================================
[2022-11-06 13:59:43.686670] Test 19, Accuracy: 0.9479166666666666
======================================================================
[2022-11-06 14:00:00.314378] Train epoch [20/30], batch: 0/530, lr: 0.00025000, loss: 0.06420414, accuracy: 1.00000000, eta: 1 day, 0:05:47
[2022-11-06 14:02:04.559052] Train epoch [20/30], batch: 100/530, lr: 0.00025000, loss: 0.23046491, accuracy: 0.92698020, eta: 2:00:39
[2022-11-06 14:04:08.996210] Train epoch [20/30], batch: 200/530, lr: 0.00025000, loss: 0.24036257, accuracy: 0.92350746, eta: 1:52:05
[2022-11-06 14:06:12.687364] Train epoch [20/30], batch: 300/530, lr: 0.00025000, loss: 0.22734573, accuracy: 0.92566445, eta: 1:47:37
[2022-11-06 14:08:17.183366] Train epoch [20/30], batch: 400/530, lr: 0.00025000, loss: 0.22223642, accuracy: 0.92783666, eta: 1:44:31
[2022-11-06 14:10:20.584298] Train epoch [20/30], batch: 500/530, lr: 0.00025000, loss: 0.22659165, accuracy: 0.92714571, eta: 1:41:39
======================================================================
[2022-11-06 14:11:05.817324] Test 20, Accuracy: 0.9375
======================================================================
[2022-11-06 14:11:22.842840] Train epoch [21/30], batch: 0/530, lr: 0.00020611, loss: 0.17742154, accuracy: 0.93750000, eta: 22:12:35
[2022-11-06 14:13:24.078561] Train epoch [21/30], batch: 100/530, lr: 0.00020611, loss: 0.20181295, accuracy: 0.93502475, eta: 1:46:20
[2022-11-06 14:15:30.109456] Train epoch [21/30], batch: 200/530, lr: 0.00020611, loss: 0.21326186, accuracy: 0.93097015, eta: 1:40:02
[2022-11-06 14:17:30.677966] Train epoch [21/30], batch: 300/530, lr: 0.00020611, loss: 0.22136410, accuracy: 0.92960963, eta: 1:35:11
[2022-11-06 14:19:38.024342] Train epoch [21/30], batch: 400/530, lr: 0.00020611, loss: 0.21538255, accuracy: 0.93048628, eta: 1:32:58
[2022-11-06 14:21:50.296543] Train epoch [21/30], batch: 500/530, lr: 0.00020611, loss: 0.20947923, accuracy: 0.93188623, eta: 1:31:30
======================================================================
[2022-11-06 14:22:32.077883] Test 21, Accuracy: 0.9375
======================================================================
[2022-11-06 14:22:48.718458] Train epoch [22/30], batch: 0/530, lr: 0.00016543, loss: 0.35918063, accuracy: 0.81250000, eta: 19:18:06
[2022-11-06 14:24:54.196831] Train epoch [22/30], batch: 100/530, lr: 0.00016543, loss: 0.22196035, accuracy: 0.92574257, eta: 1:36:55
[2022-11-06 14:27:01.269938] Train epoch [22/30], batch: 200/530, lr: 0.00016543, loss: 0.21123578, accuracy: 0.93034826, eta: 1:30:05
[2022-11-06 14:29:05.144602] Train epoch [22/30], batch: 300/530, lr: 0.00016543, loss: 0.20513645, accuracy: 0.93168605, eta: 1:25:41
[2022-11-06 14:31:07.106385] Train epoch [22/30], batch: 400/530, lr: 0.00016543, loss: 0.19917335, accuracy: 0.93344763, eta: 1:22:09
[2022-11-06 14:33:13.605028] Train epoch [22/30], batch: 500/530, lr: 0.00016543, loss: 0.19637762, accuracy: 0.93512974, eta: 1:19:47
======================================================================
[2022-11-06 14:33:58.455064] Test 22, Accuracy: 0.9479166666666666
======================================================================
[2022-11-06 14:34:15.357899] Train epoch [23/30], batch: 0/530, lr: 0.00012843, loss: 0.03204599, accuracy: 1.00000000, eta: 17:08:00
[2022-11-06 14:36:13.952689] Train epoch [23/30], batch: 100/530, lr: 0.00012843, loss: 0.19849688, accuracy: 0.93564356, eta: 1:20:33
[2022-11-06 14:38:17.123232] Train epoch [23/30], batch: 200/530, lr: 0.00012843, loss: 0.19271518, accuracy: 0.93874378, eta: 1:15:12
[2022-11-06 14:40:23.225936] Train epoch [23/30], batch: 300/530, lr: 0.00012843, loss: 0.18434627, accuracy: 0.94144518, eta: 1:12:35
[2022-11-06 14:42:24.819701] Train epoch [23/30], batch: 400/530, lr: 0.00012843, loss: 0.18581441, accuracy: 0.94046135, eta: 1:09:37
[2022-11-06 14:44:38.023411] Train epoch [23/30], batch: 500/530, lr: 0.00012843, loss: 0.18204640, accuracy: 0.94124251, eta: 1:08:15
======================================================================
[2022-11-06 14:45:21.686621] Test 23, Accuracy: 0.9583333333333334
======================================================================
[2022-11-06 14:45:38.315177] Train epoch [24/30], batch: 0/530, lr: 0.00009549, loss: 0.10177788, accuracy: 1.00000000, eta: 14:27:24
[2022-11-06 14:47:40.068517] Train epoch [24/30], batch: 100/530, lr: 0.00009549, loss: 0.18709853, accuracy: 0.93564356, eta: 1:10:11
[2022-11-06 14:49:47.845742] Train epoch [24/30], batch: 200/530, lr: 0.00009549, loss: 0.17891854, accuracy: 0.93936567, eta: 1:05:42
[2022-11-06 14:51:49.798544] Train epoch [24/30], batch: 300/530, lr: 0.00009549, loss: 0.18364099, accuracy: 0.93812292, eta: 1:01:50
[2022-11-06 14:53:58.036537] Train epoch [24/30], batch: 400/530, lr: 0.00009549, loss: 0.17924498, accuracy: 0.93874688, eta: 0:59:37
[2022-11-06 14:56:00.930827] Train epoch [24/30], batch: 500/530, lr: 0.00009549, loss: 0.17586389, accuracy: 0.94086826, eta: 0:56:57
======================================================================
[2022-11-06 14:56:46.575802] Test 24, Accuracy: 0.9479166666666666
======================================================================
[2022-11-06 14:57:01.353449] Train epoch [25/30], batch: 0/530, lr: 0.00006699, loss: 0.20779499, accuracy: 0.87500000, eta: 10:41:00
[2022-11-06 14:59:10.938841] Train epoch [25/30], batch: 100/530, lr: 0.00006699, loss: 0.14027654, accuracy: 0.95297030, eta: 1:00:38
[2022-11-06 15:01:18.483684] Train epoch [25/30], batch: 200/530, lr: 0.00006699, loss: 0.14567885, accuracy: 0.94993781, eta: 0:55:11
[2022-11-06 15:03:18.646280] Train epoch [25/30], batch: 300/530, lr: 0.00006699, loss: 0.14696094, accuracy: 0.95016611, eta: 0:50:58
[2022-11-06 15:05:25.594718] Train epoch [25/30], batch: 400/530, lr: 0.00006699, loss: 0.14585058, accuracy: 0.95230673, eta: 0:48:30
[2022-11-06 15:07:24.734051] Train epoch [25/30], batch: 500/530, lr: 0.00006699, loss: 0.14760007, accuracy: 0.95122255, eta: 0:45:37
======================================================================
[2022-11-06 15:08:12.188119] Test 25, Accuracy: 0.96875
======================================================================
[2022-11-06 15:08:29.731274] Train epoch [26/30], batch: 0/530, lr: 0.00004323, loss: 0.07077300, accuracy: 1.00000000, eta: 10:10:10
[2022-11-06 15:10:37.246200] Train epoch [26/30], batch: 100/530, lr: 0.00004323, loss: 0.16751637, accuracy: 0.94925743, eta: 0:48:15
[2022-11-06 15:12:42.135097] Train epoch [26/30], batch: 200/530, lr: 0.00004323, loss: 0.15915111, accuracy: 0.95024876, eta: 0:42:55
[2022-11-06 15:14:49.777683] Train epoch [26/30], batch: 300/530, lr: 0.00004323, loss: 0.15453917, accuracy: 0.95120432, eta: 0:40:02
[2022-11-06 15:17:10.524219] Train epoch [26/30], batch: 400/530, lr: 0.00004323, loss: 0.14999616, accuracy: 0.95246259, eta: 0:38:27
[2022-11-06 15:19:19.600969] Train epoch [26/30], batch: 500/530, lr: 0.00004323, loss: 0.14893505, accuracy: 0.95309381, eta: 0:35:57
======================================================================
[2022-11-06 15:20:21.917012] Test 26, Accuracy: 0.9479166666666666
======================================================================
[2022-11-06 15:20:36.796217] Train epoch [27/30], batch: 0/530, lr: 0.00002447, loss: 0.55604815, accuracy: 0.87500000, eta: 6:27:27
[2022-11-06 15:22:39.201807] Train epoch [27/30], batch: 100/530, lr: 0.00002447, loss: 0.13971758, accuracy: 0.95358911, eta: 0:33:41
[2022-11-06 15:24:46.213080] Train epoch [27/30], batch: 200/530, lr: 0.00002447, loss: 0.13983335, accuracy: 0.95646766, eta: 0:30:25
[2022-11-06 15:26:54.276541] Train epoch [27/30], batch: 300/530, lr: 0.00002447, loss: 0.13960333, accuracy: 0.95639535, eta: 0:28:00
[2022-11-06 15:29:01.702706] Train epoch [27/30], batch: 400/530, lr: 0.00002447, loss: 0.13941437, accuracy: 0.95557980, eta: 0:25:41
[2022-11-06 15:31:06.274504] Train epoch [27/30], batch: 500/530, lr: 0.00002447, loss: 0.14375958, accuracy: 0.95434132, eta: 0:23:21
======================================================================
[2022-11-06 15:31:53.988878] Test 27, Accuracy: 0.9479166666666666
======================================================================
[2022-11-06 15:32:10.056939] Train epoch [28/30], batch: 0/530, lr: 0.00001093, loss: 0.11730552, accuracy: 0.93750000, eta: 4:39:05
[2022-11-06 15:34:14.492102] Train epoch [28/30], batch: 100/530, lr: 0.00001093, loss: 0.13923940, accuracy: 0.96039604, eta: 0:22:12
[2022-11-06 15:36:20.531975] Train epoch [28/30], batch: 200/530, lr: 0.00001093, loss: 0.13010266, accuracy: 0.96082090, eta: 0:18:59
[2022-11-06 15:38:31.304187] Train epoch [28/30], batch: 300/530, lr: 0.00001093, loss: 0.13462992, accuracy: 0.95867940, eta: 0:16:42
[2022-11-06 15:40:33.415570] Train epoch [28/30], batch: 400/530, lr: 0.00001093, loss: 0.13150063, accuracy: 0.96009975, eta: 0:14:14
[2022-11-06 15:42:38.857042] Train epoch [28/30], batch: 500/530, lr: 0.00001093, loss: 0.13341171, accuracy: 0.95920659, eta: 0:12:00
======================================================================
[2022-11-06 15:43:43.117881] Test 28, Accuracy: 0.9583333333333334
======================================================================
[2022-11-06 15:43:59.672601] Train epoch [29/30], batch: 0/530, lr: 0.00000274, loss: 0.06561726, accuracy: 1.00000000, eta: 2:24:00
[2022-11-06 15:46:06.050569] Train epoch [29/30], batch: 100/530, lr: 0.00000274, loss: 0.11878093, accuracy: 0.96287129, eta: 0:10:07
[2022-11-06 15:48:11.230745] Train epoch [29/30], batch: 200/530, lr: 0.00000274, loss: 0.12424369, accuracy: 0.96113184, eta: 0:07:19
[2022-11-06 15:50:15.757660] Train epoch [29/30], batch: 300/530, lr: 0.00000274, loss: 0.12397382, accuracy: 0.96262458, eta: 0:04:59
[2022-11-06 15:52:19.036920] Train epoch [29/30], batch: 400/530, lr: 0.00000274, loss: 0.12440692, accuracy: 0.96197007, eta: 0:02:47
[2022-11-06 15:54:26.084095] Train epoch [29/30], batch: 500/530, lr: 0.00000274, loss: 0.12382254, accuracy: 0.96070359, eta: 0:00:38
======================================================================
[2022-11-06 15:55:12.008257] Test 29, Accuracy: 0.9583333333333334
======================================================================

Process finished with exit code 0
